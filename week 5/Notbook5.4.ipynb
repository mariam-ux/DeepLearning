{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAI612: Deep Learning & its Applications\n",
    "\n",
    "*Notebook 5.4: Predicting Housing Prices*\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/harmanani/AAI612/blob/main/Week5/Notebook5.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The MIT License (MIT)\n",
    "Copyright (c) 2021 NVIDIA\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "this software and associated documentation files (the \"Software\"), to deal in\n",
    "the Software without restriction, including without limitation the rights to\n",
    "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses a neural network to solve a regression problem, using the Boston housing dataset.  The Boston Housing dataset is included in Keras, so it is simple to access using keras.datasets.boston_housing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Read and standardize the data.\n",
    "boston_housing = keras.datasets.boston_housing\n",
    "(raw_x_train, y_train), (raw_x_test,\n",
    "    y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standardize both the training and test data by using the mean and standard deviation from the training data. The parameter axis=0 ensures that we compute the mean and standard deviation for each input variable separately. The resulting mean (and standard deviation) is a vector of means instead of a single value. That is, the standardized value of the nitric oxides concentration is not affected by the values of the per capita crime rate or any of the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.mean(raw_x_train, axis=0)\n",
    "x_stddev = np.std(raw_x_train, axis=0)\n",
    "x_train =(raw_x_train - x_mean) / x_stddev\n",
    "x_test =(raw_x_test - x_mean) / x_stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model by first instantiating the model object without any layers, and then add them one by one using the member method `add()`.\n",
    "Next, complete the missing code in the below hidden layers using 64 ReLU neurons per layer.  Careful regarding the first layer as it needs to match the match the dataset. The output layer consists of a single neuron with a linear activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create and train model.\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=[raw_x_train.shape[1]]))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use MSE as the loss function and use the `Adam` optimizer and compile method that we are interested in seeing the metric mean absolute error, and print out a summary of the model with `model.summary()` and then start training.  Experiment with different `batch sizes` and `epochs`.  Record the results for these experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,121</span> (20.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,121\u001b[0m (20.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,121</span> (20.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,121\u001b[0m (20.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\ops\\nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 2s - 64ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 2/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 3/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 4/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 5/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 6/500\n",
      "26/26 - 0s - 13ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 7/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 8/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 9/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 10/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 11/500\n",
      "26/26 - 0s - 13ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 12/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 13/500\n",
      "26/26 - 0s - 15ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 14/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 15/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 16/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 17/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 18/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 19/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 20/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 21/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 22/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 23/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 24/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 25/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 26/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 27/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 28/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 29/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 30/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 31/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 32/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 33/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 34/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 35/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 36/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 37/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 38/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 39/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 40/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 41/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 42/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 43/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 44/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 45/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 46/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 47/500\n",
      "26/26 - 0s - 11ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 48/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 49/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 50/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 51/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 52/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 53/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 54/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 55/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 56/500\n",
      "26/26 - 0s - 11ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 57/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 58/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 59/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 60/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 61/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 62/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 63/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 64/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 65/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 66/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 67/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 68/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 69/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 70/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 71/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 72/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 73/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 74/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 75/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 76/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 77/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 78/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 79/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 80/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 81/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 82/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 83/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 84/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 85/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 86/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 87/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 88/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 89/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 90/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 91/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 92/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 93/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 94/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 95/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 96/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 97/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 98/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 99/500\n",
      "26/26 - 0s - 11ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 100/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 101/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 102/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 103/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 104/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 105/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 106/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 107/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 108/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 109/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 110/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 111/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 112/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 113/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 114/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 115/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 116/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 117/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 118/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 119/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 120/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 121/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 122/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 123/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 124/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 125/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 126/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 127/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 128/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 129/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 130/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 131/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 132/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 133/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 134/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 135/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 136/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 137/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 138/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 139/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 140/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 141/500\n",
      "26/26 - 0s - 11ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 142/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 143/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 144/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 145/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 146/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 147/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 148/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 149/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 150/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 151/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 152/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 153/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 154/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 155/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 156/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 157/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 158/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 159/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 160/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 161/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 162/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 163/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 164/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 165/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 166/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 167/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 168/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 169/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 170/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 171/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 172/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 173/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 174/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 175/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 176/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 177/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 178/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 179/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 180/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 181/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 182/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 183/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 184/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 185/500\n",
      "26/26 - 0s - 10ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 186/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 187/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 188/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 189/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 190/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 191/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 192/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 193/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 194/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 195/500\n",
      "26/26 - 0s - 9ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 196/500\n",
      "26/26 - 0s - 9ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 197/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 198/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 199/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 200/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 201/500\n",
      "26/26 - 0s - 14ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 202/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 203/500\n",
      "26/26 - 0s - 10ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 204/500\n",
      "26/26 - 0s - 10ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 205/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 206/500\n",
      "26/26 - 0s - 16ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 207/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 208/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 209/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 210/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 211/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 212/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 213/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 214/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 215/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 216/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 217/500\n",
      "26/26 - 0s - 9ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 218/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 219/500\n",
      "26/26 - 0s - 9ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 220/500\n",
      "26/26 - 0s - 13ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 221/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 222/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 223/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 224/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 225/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 226/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 227/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 228/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 229/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 230/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 231/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 232/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 233/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 234/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 235/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 236/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 237/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 238/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 239/500\n",
      "26/26 - 0s - 18ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 240/500\n",
      "26/26 - 1s - 21ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 241/500\n",
      "26/26 - 0s - 14ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 242/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 243/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 244/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 245/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 246/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 247/500\n",
      "26/26 - 0s - 14ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 248/500\n",
      "26/26 - 0s - 10ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 249/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 250/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 251/500\n",
      "26/26 - 0s - 13ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 252/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 253/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 254/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 255/500\n",
      "26/26 - 0s - 9ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 256/500\n",
      "26/26 - 0s - 11ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 257/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 258/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 259/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 260/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 261/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 262/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 263/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 264/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 265/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 266/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 267/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 268/500\n",
      "26/26 - 0s - 15ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 269/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 270/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 271/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 272/500\n",
      "26/26 - 0s - 13ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 273/500\n",
      "26/26 - 0s - 10ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 274/500\n",
      "26/26 - 0s - 9ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 275/500\n",
      "26/26 - 0s - 11ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 276/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 277/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 278/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 279/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 280/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 281/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 282/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 283/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 284/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 285/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 286/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 287/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 288/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 289/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 290/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 291/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 292/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 293/500\n",
      "26/26 - 0s - 8ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 294/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 295/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 296/500\n",
      "26/26 - 0s - 9ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 297/500\n",
      "26/26 - 0s - 13ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 298/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 299/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 300/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 301/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 302/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 303/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 304/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 305/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 306/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 307/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 308/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 309/500\n",
      "26/26 - 0s - 11ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 310/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 311/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 312/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 313/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 314/500\n",
      "26/26 - 0s - 13ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 315/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 316/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 317/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 318/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 319/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 320/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 321/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 322/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 323/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 324/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 325/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 326/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 327/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 328/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 329/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 330/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 331/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 332/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 333/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 334/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 335/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 336/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 337/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 338/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 339/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 340/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 341/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 342/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 343/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 344/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 345/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 346/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 347/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 348/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 349/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 350/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 351/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 352/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 353/500\n",
      "26/26 - 0s - 9ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 354/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 355/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 356/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 357/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 358/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 359/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 360/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 361/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 362/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 363/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 364/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 365/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 366/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 367/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 368/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 369/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 370/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 371/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 372/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 373/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 374/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 375/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 376/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 377/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 378/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 379/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 380/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 381/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 382/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 383/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 384/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 385/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 386/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 387/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 388/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 389/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 390/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 391/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 392/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 393/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 394/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 395/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 396/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 397/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 398/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 399/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 400/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 401/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 402/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 403/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 404/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 405/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 406/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 407/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 408/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 409/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 410/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 411/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 412/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 413/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 414/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 415/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 416/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 417/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 418/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 419/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 420/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 421/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 422/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 423/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 424/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 425/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 426/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 427/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 428/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 429/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 430/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 431/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 432/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 433/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 434/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 435/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 436/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 437/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 438/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 439/500\n",
      "26/26 - 0s - 10ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 440/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 441/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 442/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 443/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 444/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 445/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 446/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 447/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 448/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 449/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 450/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 451/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 452/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 453/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 454/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 455/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 456/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 457/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 458/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 459/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 460/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 461/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 462/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 463/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 464/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 465/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 466/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 467/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 468/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 469/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 470/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 471/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 472/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 473/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 474/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 475/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 476/500\n",
      "26/26 - 0s - 12ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 477/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 478/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 479/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 480/500\n",
      "26/26 - 0s - 10ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 481/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 482/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 483/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 484/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 485/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 486/500\n",
      "26/26 - 0s - 7ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 487/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 488/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 489/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 490/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 491/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 492/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 493/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3703 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 494/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 495/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3705 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 496/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 497/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 498/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3950 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 499/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n",
      "Epoch 500/500\n",
      "26/26 - 0s - 6ms/step - loss: 542.3704 - mean_absolute_error: 21.3951 - val_loss: 570.7009 - val_mean_absolute_error: 22.0784\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 500\n",
    "\n",
    "model.compile(loss='mse', optimizer='Adam', metrics =['mean_absolute_error'])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training is done, we use our model to predict the price for the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\ops\\nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the answers, let us check how far off you are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected =[7.939793, 18.455063, 20.115505, 32.14037]\n",
    "for i in range(0, 4):\n",
    "    assert ((predictions[i] - expected[i]) < 0.0001), \"predicted value is too large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the above results by modifying the network to include more layers with more neurons.  Also, apply L1 and L2 regularization using different weight decay parameters: Start with $\\lambda=0.1$ and try $\\lambda=0.2$ and $\\lambda=0.3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,785</span> (120.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,785\u001b[0m (120.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,785</span> (120.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,785\u001b[0m (120.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 - 3s - 105ms/step - loss: 1075.2307 - mae: 21.3827 - val_loss: 930.9005 - val_mae: 19.1067\n",
      "Epoch 2/500\n",
      "26/26 - 0s - 7ms/step - loss: 663.4443 - mae: 11.1894 - val_loss: 499.3057 - val_mae: 6.8826\n",
      "Epoch 3/500\n",
      "26/26 - 0s - 6ms/step - loss: 461.2032 - mae: 6.3376 - val_loss: 392.5522 - val_mae: 4.5877\n",
      "Epoch 4/500\n",
      "26/26 - 0s - 7ms/step - loss: 381.9635 - mae: 5.5798 - val_loss: 331.5688 - val_mae: 4.1369\n",
      "Epoch 5/500\n",
      "26/26 - 0s - 14ms/step - loss: 321.2321 - mae: 4.9724 - val_loss: 278.1147 - val_mae: 3.5817\n",
      "Epoch 6/500\n",
      "26/26 - 0s - 8ms/step - loss: 272.3720 - mae: 4.6274 - val_loss: 240.3749 - val_mae: 3.6026\n",
      "Epoch 7/500\n",
      "26/26 - 0s - 6ms/step - loss: 241.0243 - mae: 4.6089 - val_loss: 214.9627 - val_mae: 3.8533\n",
      "Epoch 8/500\n",
      "26/26 - 0s - 8ms/step - loss: 211.8093 - mae: 4.3601 - val_loss: 195.0934 - val_mae: 4.1589\n",
      "Epoch 9/500\n",
      "26/26 - 0s - 7ms/step - loss: 192.8360 - mae: 4.3042 - val_loss: 176.1625 - val_mae: 3.8285\n",
      "Epoch 10/500\n",
      "26/26 - 0s - 7ms/step - loss: 173.6117 - mae: 4.1161 - val_loss: 159.2567 - val_mae: 3.4008\n",
      "Epoch 11/500\n",
      "26/26 - 0s - 6ms/step - loss: 159.9836 - mae: 4.0885 - val_loss: 148.0496 - val_mae: 3.3907\n",
      "Epoch 12/500\n",
      "26/26 - 0s - 6ms/step - loss: 150.0413 - mae: 4.1532 - val_loss: 137.7084 - val_mae: 3.2432\n",
      "Epoch 13/500\n",
      "26/26 - 0s - 6ms/step - loss: 140.2651 - mae: 3.9201 - val_loss: 131.0391 - val_mae: 3.2914\n",
      "Epoch 14/500\n",
      "26/26 - 0s - 6ms/step - loss: 136.8871 - mae: 4.2047 - val_loss: 123.3840 - val_mae: 3.3259\n",
      "Epoch 15/500\n",
      "26/26 - 0s - 6ms/step - loss: 125.8300 - mae: 3.8799 - val_loss: 117.7876 - val_mae: 3.3711\n",
      "Epoch 16/500\n",
      "26/26 - 0s - 6ms/step - loss: 125.0005 - mae: 4.0394 - val_loss: 111.7392 - val_mae: 3.1704\n",
      "Epoch 17/500\n",
      "26/26 - 0s - 6ms/step - loss: 115.3023 - mae: 3.7885 - val_loss: 109.7011 - val_mae: 3.4527\n",
      "Epoch 18/500\n",
      "26/26 - 0s - 6ms/step - loss: 114.1544 - mae: 3.9784 - val_loss: 104.3743 - val_mae: 3.3020\n",
      "Epoch 19/500\n",
      "26/26 - 0s - 6ms/step - loss: 109.8160 - mae: 3.7674 - val_loss: 101.2913 - val_mae: 3.2752\n",
      "Epoch 20/500\n",
      "26/26 - 0s - 6ms/step - loss: 105.2178 - mae: 3.7451 - val_loss: 97.4394 - val_mae: 3.2854\n",
      "Epoch 21/500\n",
      "26/26 - 0s - 6ms/step - loss: 99.0962 - mae: 3.7991 - val_loss: 94.3566 - val_mae: 3.2045\n",
      "Epoch 22/500\n",
      "26/26 - 0s - 6ms/step - loss: 94.3944 - mae: 3.5910 - val_loss: 92.0014 - val_mae: 3.2395\n",
      "Epoch 23/500\n",
      "26/26 - 0s - 7ms/step - loss: 95.9694 - mae: 3.8128 - val_loss: 91.8286 - val_mae: 3.4799\n",
      "Epoch 24/500\n",
      "26/26 - 0s - 6ms/step - loss: 95.4283 - mae: 3.7125 - val_loss: 85.5935 - val_mae: 3.1063\n",
      "Epoch 25/500\n",
      "26/26 - 0s - 12ms/step - loss: 89.8197 - mae: 3.7429 - val_loss: 84.7113 - val_mae: 3.1325\n",
      "Epoch 26/500\n",
      "26/26 - 0s - 9ms/step - loss: 90.4717 - mae: 3.7149 - val_loss: 85.0017 - val_mae: 3.4380\n",
      "Epoch 27/500\n",
      "26/26 - 0s - 7ms/step - loss: 87.3472 - mae: 3.6679 - val_loss: 81.6301 - val_mae: 3.2118\n",
      "Epoch 28/500\n",
      "26/26 - 0s - 8ms/step - loss: 84.6980 - mae: 3.5543 - val_loss: 79.2683 - val_mae: 3.2158\n",
      "Epoch 29/500\n",
      "26/26 - 0s - 7ms/step - loss: 86.8560 - mae: 3.7619 - val_loss: 78.9741 - val_mae: 3.3093\n",
      "Epoch 30/500\n",
      "26/26 - 0s - 7ms/step - loss: 85.2823 - mae: 3.8454 - val_loss: 79.5625 - val_mae: 3.5347\n",
      "Epoch 31/500\n",
      "26/26 - 0s - 7ms/step - loss: 83.9977 - mae: 3.9218 - val_loss: 79.0351 - val_mae: 3.5344\n",
      "Epoch 32/500\n",
      "26/26 - 0s - 7ms/step - loss: 80.2579 - mae: 3.6697 - val_loss: 76.3237 - val_mae: 3.2431\n",
      "Epoch 33/500\n",
      "26/26 - 0s - 7ms/step - loss: 77.3037 - mae: 3.5524 - val_loss: 75.2716 - val_mae: 3.2261\n",
      "Epoch 34/500\n",
      "26/26 - 0s - 7ms/step - loss: 79.3006 - mae: 3.7950 - val_loss: 73.9633 - val_mae: 3.1795\n",
      "Epoch 35/500\n",
      "26/26 - 0s - 6ms/step - loss: 75.3778 - mae: 3.6141 - val_loss: 75.7212 - val_mae: 3.7239\n",
      "Epoch 36/500\n",
      "26/26 - 0s - 7ms/step - loss: 74.2967 - mae: 3.4648 - val_loss: 73.3624 - val_mae: 3.5690\n",
      "Epoch 37/500\n",
      "26/26 - 0s - 7ms/step - loss: 73.2842 - mae: 3.5311 - val_loss: 72.2383 - val_mae: 3.3873\n",
      "Epoch 38/500\n",
      "26/26 - 0s - 7ms/step - loss: 75.9786 - mae: 3.6366 - val_loss: 71.1373 - val_mae: 3.3646\n",
      "Epoch 39/500\n",
      "26/26 - 0s - 6ms/step - loss: 71.0572 - mae: 3.4774 - val_loss: 70.6360 - val_mae: 3.2090\n",
      "Epoch 40/500\n",
      "26/26 - 0s - 7ms/step - loss: 73.9477 - mae: 3.5798 - val_loss: 69.8775 - val_mae: 3.1549\n",
      "Epoch 41/500\n",
      "26/26 - 0s - 7ms/step - loss: 72.7026 - mae: 3.6837 - val_loss: 69.2448 - val_mae: 3.2258\n",
      "Epoch 42/500\n",
      "26/26 - 0s - 7ms/step - loss: 68.8979 - mae: 3.4644 - val_loss: 67.5840 - val_mae: 3.2582\n",
      "Epoch 43/500\n",
      "26/26 - 0s - 7ms/step - loss: 69.2152 - mae: 3.6086 - val_loss: 67.5264 - val_mae: 3.2889\n",
      "Epoch 44/500\n",
      "26/26 - 0s - 7ms/step - loss: 66.3823 - mae: 3.5135 - val_loss: 66.5093 - val_mae: 3.3688\n",
      "Epoch 45/500\n",
      "26/26 - 0s - 6ms/step - loss: 69.2904 - mae: 3.6362 - val_loss: 66.5682 - val_mae: 3.3189\n",
      "Epoch 46/500\n",
      "26/26 - 0s - 6ms/step - loss: 67.1981 - mae: 3.6246 - val_loss: 63.2792 - val_mae: 3.1839\n",
      "Epoch 47/500\n",
      "26/26 - 0s - 6ms/step - loss: 67.2476 - mae: 3.6563 - val_loss: 62.8656 - val_mae: 3.1992\n",
      "Epoch 48/500\n",
      "26/26 - 0s - 6ms/step - loss: 64.6629 - mae: 3.4191 - val_loss: 63.8662 - val_mae: 3.3579\n",
      "Epoch 49/500\n",
      "26/26 - 0s - 6ms/step - loss: 62.9204 - mae: 3.4981 - val_loss: 62.5257 - val_mae: 3.3152\n",
      "Epoch 50/500\n",
      "26/26 - 0s - 7ms/step - loss: 64.3234 - mae: 3.4511 - val_loss: 60.7781 - val_mae: 3.2253\n",
      "Epoch 51/500\n",
      "26/26 - 0s - 6ms/step - loss: 61.6360 - mae: 3.3830 - val_loss: 60.6572 - val_mae: 3.1186\n",
      "Epoch 52/500\n",
      "26/26 - 0s - 6ms/step - loss: 66.4923 - mae: 3.6471 - val_loss: 61.2734 - val_mae: 3.4094\n",
      "Epoch 53/500\n",
      "26/26 - 0s - 6ms/step - loss: 63.1006 - mae: 3.5079 - val_loss: 59.7850 - val_mae: 3.1319\n",
      "Epoch 54/500\n",
      "26/26 - 0s - 6ms/step - loss: 59.0204 - mae: 3.3123 - val_loss: 61.2999 - val_mae: 3.5422\n",
      "Epoch 55/500\n",
      "26/26 - 0s - 6ms/step - loss: 59.6281 - mae: 3.3808 - val_loss: 61.4167 - val_mae: 3.6286\n",
      "Epoch 56/500\n",
      "26/26 - 0s - 7ms/step - loss: 59.6721 - mae: 3.4816 - val_loss: 59.5716 - val_mae: 3.1795\n",
      "Epoch 57/500\n",
      "26/26 - 0s - 6ms/step - loss: 60.4112 - mae: 3.5076 - val_loss: 59.2820 - val_mae: 3.2009\n",
      "Epoch 58/500\n",
      "26/26 - 0s - 6ms/step - loss: 61.5721 - mae: 3.5792 - val_loss: 59.4557 - val_mae: 3.3687\n",
      "Epoch 59/500\n",
      "26/26 - 0s - 7ms/step - loss: 58.1692 - mae: 3.4635 - val_loss: 59.0125 - val_mae: 3.4479\n",
      "Epoch 60/500\n",
      "26/26 - 0s - 7ms/step - loss: 60.1172 - mae: 3.5566 - val_loss: 57.4770 - val_mae: 3.2661\n",
      "Epoch 61/500\n",
      "26/26 - 0s - 6ms/step - loss: 57.2601 - mae: 3.3344 - val_loss: 57.3063 - val_mae: 3.2927\n",
      "Epoch 62/500\n",
      "26/26 - 0s - 6ms/step - loss: 61.4952 - mae: 3.5378 - val_loss: 58.9197 - val_mae: 3.6766\n",
      "Epoch 63/500\n",
      "26/26 - 0s - 6ms/step - loss: 60.6429 - mae: 3.6974 - val_loss: 55.1708 - val_mae: 3.2012\n",
      "Epoch 64/500\n",
      "26/26 - 0s - 7ms/step - loss: 57.9129 - mae: 3.4861 - val_loss: 57.2364 - val_mae: 3.5141\n",
      "Epoch 65/500\n",
      "26/26 - 0s - 6ms/step - loss: 62.9274 - mae: 3.5753 - val_loss: 54.9456 - val_mae: 3.1900\n",
      "Epoch 66/500\n",
      "26/26 - 0s - 6ms/step - loss: 57.4322 - mae: 3.5665 - val_loss: 55.9577 - val_mae: 3.2545\n",
      "Epoch 67/500\n",
      "26/26 - 0s - 7ms/step - loss: 60.5478 - mae: 3.6851 - val_loss: 55.2012 - val_mae: 3.1794\n",
      "Epoch 68/500\n",
      "26/26 - 0s - 7ms/step - loss: 58.3015 - mae: 3.5724 - val_loss: 56.0351 - val_mae: 3.3195\n",
      "Epoch 69/500\n",
      "26/26 - 0s - 6ms/step - loss: 58.2591 - mae: 3.5607 - val_loss: 55.5105 - val_mae: 3.2394\n",
      "Epoch 70/500\n",
      "26/26 - 0s - 6ms/step - loss: 55.4248 - mae: 3.4591 - val_loss: 56.0380 - val_mae: 3.5737\n",
      "Epoch 71/500\n",
      "26/26 - 0s - 6ms/step - loss: 57.0325 - mae: 3.5862 - val_loss: 54.8951 - val_mae: 3.3992\n",
      "Epoch 72/500\n",
      "26/26 - 0s - 6ms/step - loss: 54.4740 - mae: 3.3269 - val_loss: 53.6168 - val_mae: 3.1708\n",
      "Epoch 73/500\n",
      "26/26 - 0s - 6ms/step - loss: 53.8154 - mae: 3.4684 - val_loss: 55.3655 - val_mae: 3.4976\n",
      "Epoch 74/500\n",
      "26/26 - 0s - 12ms/step - loss: 56.2847 - mae: 3.5330 - val_loss: 54.1260 - val_mae: 3.2583\n",
      "Epoch 75/500\n",
      "26/26 - 0s - 6ms/step - loss: 53.7955 - mae: 3.4525 - val_loss: 55.5572 - val_mae: 3.5529\n",
      "Epoch 76/500\n",
      "26/26 - 0s - 6ms/step - loss: 55.2770 - mae: 3.5389 - val_loss: 56.3259 - val_mae: 3.7250\n",
      "Epoch 77/500\n",
      "26/26 - 0s - 12ms/step - loss: 54.6575 - mae: 3.5236 - val_loss: 54.0759 - val_mae: 3.3653\n",
      "Epoch 78/500\n",
      "26/26 - 0s - 6ms/step - loss: 55.3651 - mae: 3.4943 - val_loss: 53.9264 - val_mae: 3.2740\n",
      "Epoch 79/500\n",
      "26/26 - 0s - 6ms/step - loss: 51.5035 - mae: 3.3977 - val_loss: 54.1450 - val_mae: 3.3034\n",
      "Epoch 80/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.9777 - mae: 3.3577 - val_loss: 54.1230 - val_mae: 3.4267\n",
      "Epoch 81/500\n",
      "26/26 - 0s - 6ms/step - loss: 52.4888 - mae: 3.4341 - val_loss: 54.0863 - val_mae: 3.4104\n",
      "Epoch 82/500\n",
      "26/26 - 0s - 11ms/step - loss: 53.1770 - mae: 3.4213 - val_loss: 55.3745 - val_mae: 3.6904\n",
      "Epoch 83/500\n",
      "26/26 - 0s - 7ms/step - loss: 54.6709 - mae: 3.4472 - val_loss: 53.0445 - val_mae: 3.3972\n",
      "Epoch 84/500\n",
      "26/26 - 0s - 6ms/step - loss: 54.1619 - mae: 3.4539 - val_loss: 52.1035 - val_mae: 3.2930\n",
      "Epoch 85/500\n",
      "26/26 - 0s - 6ms/step - loss: 51.8037 - mae: 3.2910 - val_loss: 52.8833 - val_mae: 3.3975\n",
      "Epoch 86/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.6545 - mae: 3.2268 - val_loss: 52.6332 - val_mae: 3.2944\n",
      "Epoch 87/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.5356 - mae: 3.2969 - val_loss: 53.0248 - val_mae: 3.4539\n",
      "Epoch 88/500\n",
      "26/26 - 0s - 7ms/step - loss: 53.9395 - mae: 3.6094 - val_loss: 56.0019 - val_mae: 3.8478\n",
      "Epoch 89/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.3881 - mae: 3.2956 - val_loss: 52.4653 - val_mae: 3.2895\n",
      "Epoch 90/500\n",
      "26/26 - 0s - 6ms/step - loss: 53.1424 - mae: 3.5328 - val_loss: 51.8400 - val_mae: 3.2773\n",
      "Epoch 91/500\n",
      "26/26 - 0s - 6ms/step - loss: 51.1979 - mae: 3.4326 - val_loss: 53.0423 - val_mae: 3.3456\n",
      "Epoch 92/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.9982 - mae: 3.3343 - val_loss: 52.7060 - val_mae: 3.4667\n",
      "Epoch 93/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.9649 - mae: 3.3993 - val_loss: 53.0414 - val_mae: 3.3142\n",
      "Epoch 94/500\n",
      "26/26 - 0s - 6ms/step - loss: 51.1204 - mae: 3.4224 - val_loss: 53.0117 - val_mae: 3.3708\n",
      "Epoch 95/500\n",
      "26/26 - 0s - 6ms/step - loss: 51.3129 - mae: 3.4731 - val_loss: 54.5496 - val_mae: 3.6792\n",
      "Epoch 96/500\n",
      "26/26 - 0s - 6ms/step - loss: 53.5040 - mae: 3.6254 - val_loss: 55.3043 - val_mae: 3.8875\n",
      "Epoch 97/500\n",
      "26/26 - 0s - 6ms/step - loss: 51.1448 - mae: 3.4294 - val_loss: 52.3667 - val_mae: 3.5207\n",
      "Epoch 98/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.8843 - mae: 3.2659 - val_loss: 53.7643 - val_mae: 3.7704\n",
      "Epoch 99/500\n",
      "26/26 - 0s - 7ms/step - loss: 50.5862 - mae: 3.4036 - val_loss: 52.9164 - val_mae: 3.6531\n",
      "Epoch 100/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.2191 - mae: 3.4306 - val_loss: 52.2987 - val_mae: 3.3617\n",
      "Epoch 101/500\n",
      "26/26 - 0s - 12ms/step - loss: 52.2699 - mae: 3.5076 - val_loss: 51.7633 - val_mae: 3.4001\n",
      "Epoch 102/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.5154 - mae: 3.3939 - val_loss: 51.5114 - val_mae: 3.5401\n",
      "Epoch 103/500\n",
      "26/26 - 0s - 7ms/step - loss: 50.5308 - mae: 3.4009 - val_loss: 51.8823 - val_mae: 3.2918\n",
      "Epoch 104/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.4354 - mae: 3.3157 - val_loss: 52.6840 - val_mae: 3.6344\n",
      "Epoch 105/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.6516 - mae: 3.4465 - val_loss: 51.1641 - val_mae: 3.4814\n",
      "Epoch 106/500\n",
      "26/26 - 0s - 6ms/step - loss: 51.7561 - mae: 3.4951 - val_loss: 52.4450 - val_mae: 3.6858\n",
      "Epoch 107/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.4642 - mae: 3.4939 - val_loss: 50.9494 - val_mae: 3.4723\n",
      "Epoch 108/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.5585 - mae: 3.3045 - val_loss: 50.6572 - val_mae: 3.3278\n",
      "Epoch 109/500\n",
      "26/26 - 0s - 6ms/step - loss: 48.8653 - mae: 3.3840 - val_loss: 50.9175 - val_mae: 3.4323\n",
      "Epoch 110/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.6006 - mae: 3.4411 - val_loss: 53.7183 - val_mae: 3.7511\n",
      "Epoch 111/500\n",
      "26/26 - 0s - 7ms/step - loss: 49.6137 - mae: 3.4370 - val_loss: 51.0926 - val_mae: 3.3852\n",
      "Epoch 112/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.3342 - mae: 3.3704 - val_loss: 51.1608 - val_mae: 3.3793\n",
      "Epoch 113/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.9188 - mae: 3.0905 - val_loss: 51.3884 - val_mae: 3.3240\n",
      "Epoch 114/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.4234 - mae: 3.4655 - val_loss: 50.1603 - val_mae: 3.4114\n",
      "Epoch 115/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.8782 - mae: 3.3881 - val_loss: 50.9782 - val_mae: 3.4169\n",
      "Epoch 116/500\n",
      "26/26 - 0s - 12ms/step - loss: 50.4015 - mae: 3.4083 - val_loss: 51.5556 - val_mae: 3.5279\n",
      "Epoch 117/500\n",
      "26/26 - 0s - 6ms/step - loss: 51.4176 - mae: 3.5830 - val_loss: 50.4212 - val_mae: 3.4741\n",
      "Epoch 118/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.7540 - mae: 3.3839 - val_loss: 51.5323 - val_mae: 3.2751\n",
      "Epoch 119/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.7000 - mae: 3.3805 - val_loss: 49.3071 - val_mae: 3.3942\n",
      "Epoch 120/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.5311 - mae: 3.3731 - val_loss: 49.8254 - val_mae: 3.3824\n",
      "Epoch 121/500\n",
      "26/26 - 0s - 7ms/step - loss: 51.2321 - mae: 3.5819 - val_loss: 55.1058 - val_mae: 4.0917\n",
      "Epoch 122/500\n",
      "26/26 - 0s - 8ms/step - loss: 48.8348 - mae: 3.4013 - val_loss: 49.6964 - val_mae: 3.2847\n",
      "Epoch 123/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.2681 - mae: 3.4086 - val_loss: 50.7084 - val_mae: 3.4385\n",
      "Epoch 124/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.9814 - mae: 3.3054 - val_loss: 49.6007 - val_mae: 3.5044\n",
      "Epoch 125/500\n",
      "26/26 - 0s - 12ms/step - loss: 53.5498 - mae: 3.5831 - val_loss: 49.8292 - val_mae: 3.4553\n",
      "Epoch 126/500\n",
      "26/26 - 0s - 6ms/step - loss: 48.3902 - mae: 3.3817 - val_loss: 48.4385 - val_mae: 3.2481\n",
      "Epoch 127/500\n",
      "26/26 - 0s - 13ms/step - loss: 50.5588 - mae: 3.5316 - val_loss: 49.1855 - val_mae: 3.4546\n",
      "Epoch 128/500\n",
      "26/26 - 0s - 7ms/step - loss: 48.0496 - mae: 3.3805 - val_loss: 50.2829 - val_mae: 3.5280\n",
      "Epoch 129/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.5214 - mae: 3.6040 - val_loss: 50.3920 - val_mae: 3.5053\n",
      "Epoch 130/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.0946 - mae: 3.4077 - val_loss: 49.8901 - val_mae: 3.3880\n",
      "Epoch 131/500\n",
      "26/26 - 0s - 6ms/step - loss: 48.3215 - mae: 3.3062 - val_loss: 51.4516 - val_mae: 3.7560\n",
      "Epoch 132/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.9048 - mae: 3.4679 - val_loss: 49.8801 - val_mae: 3.3440\n",
      "Epoch 133/500\n",
      "26/26 - 0s - 7ms/step - loss: 48.4595 - mae: 3.3691 - val_loss: 50.2836 - val_mae: 3.3758\n",
      "Epoch 134/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.5979 - mae: 3.6159 - val_loss: 52.0745 - val_mae: 3.6519\n",
      "Epoch 135/500\n",
      "26/26 - 0s - 7ms/step - loss: 47.0812 - mae: 3.3426 - val_loss: 51.8540 - val_mae: 3.4557\n",
      "Epoch 136/500\n",
      "26/26 - 0s - 7ms/step - loss: 46.1393 - mae: 3.4401 - val_loss: 53.0647 - val_mae: 3.5916\n",
      "Epoch 137/500\n",
      "26/26 - 0s - 7ms/step - loss: 46.2202 - mae: 3.2790 - val_loss: 49.7939 - val_mae: 3.3934\n",
      "Epoch 138/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.4421 - mae: 3.2161 - val_loss: 50.3784 - val_mae: 3.6900\n",
      "Epoch 139/500\n",
      "26/26 - 0s - 6ms/step - loss: 48.4359 - mae: 3.4953 - val_loss: 48.6890 - val_mae: 3.5166\n",
      "Epoch 140/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.5763 - mae: 3.3840 - val_loss: 47.7358 - val_mae: 3.3949\n",
      "Epoch 141/500\n",
      "26/26 - 0s - 6ms/step - loss: 49.1932 - mae: 3.5331 - val_loss: 48.2105 - val_mae: 3.3426\n",
      "Epoch 142/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.1730 - mae: 3.3915 - val_loss: 47.0590 - val_mae: 3.2416\n",
      "Epoch 143/500\n",
      "26/26 - 0s - 6ms/step - loss: 48.5676 - mae: 3.4482 - val_loss: 46.4444 - val_mae: 3.2621\n",
      "Epoch 144/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.5360 - mae: 3.4459 - val_loss: 48.0357 - val_mae: 3.4720\n",
      "Epoch 145/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.3269 - mae: 3.3282 - val_loss: 47.7011 - val_mae: 3.4495\n",
      "Epoch 146/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.9204 - mae: 3.2648 - val_loss: 47.9036 - val_mae: 3.4828\n",
      "Epoch 147/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.2103 - mae: 3.3697 - val_loss: 47.4127 - val_mae: 3.2288\n",
      "Epoch 148/500\n",
      "26/26 - 0s - 6ms/step - loss: 45.9540 - mae: 3.3504 - val_loss: 48.6036 - val_mae: 3.4138\n",
      "Epoch 149/500\n",
      "26/26 - 0s - 7ms/step - loss: 45.2119 - mae: 3.2623 - val_loss: 49.9134 - val_mae: 3.5592\n",
      "Epoch 150/500\n",
      "26/26 - 0s - 7ms/step - loss: 49.0901 - mae: 3.5968 - val_loss: 49.1022 - val_mae: 3.5871\n",
      "Epoch 151/500\n",
      "26/26 - 0s - 8ms/step - loss: 44.1780 - mae: 3.2875 - val_loss: 49.3128 - val_mae: 3.6390\n",
      "Epoch 152/500\n",
      "26/26 - 0s - 10ms/step - loss: 47.1983 - mae: 3.4203 - val_loss: 48.7766 - val_mae: 3.3834\n",
      "Epoch 153/500\n",
      "26/26 - 0s - 7ms/step - loss: 45.9255 - mae: 3.4231 - val_loss: 48.4833 - val_mae: 3.3272\n",
      "Epoch 154/500\n",
      "26/26 - 0s - 7ms/step - loss: 47.2448 - mae: 3.4587 - val_loss: 48.7474 - val_mae: 3.6114\n",
      "Epoch 155/500\n",
      "26/26 - 0s - 7ms/step - loss: 48.1027 - mae: 3.4474 - val_loss: 50.9159 - val_mae: 3.8774\n",
      "Epoch 156/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.2952 - mae: 3.2883 - val_loss: 47.0043 - val_mae: 3.3366\n",
      "Epoch 157/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.3290 - mae: 3.3960 - val_loss: 48.5653 - val_mae: 3.5277\n",
      "Epoch 158/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.6451 - mae: 3.2601 - val_loss: 48.1146 - val_mae: 3.3605\n",
      "Epoch 159/500\n",
      "26/26 - 0s - 6ms/step - loss: 45.2019 - mae: 3.2302 - val_loss: 45.2148 - val_mae: 3.2626\n",
      "Epoch 160/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.8311 - mae: 3.2867 - val_loss: 46.0848 - val_mae: 3.3025\n",
      "Epoch 161/500\n",
      "26/26 - 0s - 7ms/step - loss: 48.6453 - mae: 3.5578 - val_loss: 48.1289 - val_mae: 3.5759\n",
      "Epoch 162/500\n",
      "26/26 - 0s - 7ms/step - loss: 43.9570 - mae: 3.2781 - val_loss: 47.7567 - val_mae: 3.5186\n",
      "Epoch 163/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.3115 - mae: 3.4214 - val_loss: 46.8306 - val_mae: 3.4542\n",
      "Epoch 164/500\n",
      "26/26 - 0s - 7ms/step - loss: 45.8703 - mae: 3.3472 - val_loss: 45.8416 - val_mae: 3.3624\n",
      "Epoch 165/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.0972 - mae: 3.5021 - val_loss: 47.7391 - val_mae: 3.4837\n",
      "Epoch 166/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.3750 - mae: 3.4572 - val_loss: 47.9280 - val_mae: 3.5552\n",
      "Epoch 167/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.6596 - mae: 3.3788 - val_loss: 51.8589 - val_mae: 3.8859\n",
      "Epoch 168/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.6005 - mae: 3.4690 - val_loss: 50.0976 - val_mae: 3.7321\n",
      "Epoch 169/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.7946 - mae: 3.0466 - val_loss: 47.9258 - val_mae: 3.4028\n",
      "Epoch 170/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.0326 - mae: 3.2642 - val_loss: 48.6045 - val_mae: 3.5427\n",
      "Epoch 171/500\n",
      "26/26 - 0s - 12ms/step - loss: 42.7182 - mae: 3.1879 - val_loss: 47.9485 - val_mae: 3.3594\n",
      "Epoch 172/500\n",
      "26/26 - 0s - 13ms/step - loss: 45.7697 - mae: 3.4189 - val_loss: 49.8840 - val_mae: 3.8289\n",
      "Epoch 173/500\n",
      "26/26 - 0s - 7ms/step - loss: 53.3415 - mae: 3.7907 - val_loss: 47.7987 - val_mae: 3.5189\n",
      "Epoch 174/500\n",
      "26/26 - 0s - 6ms/step - loss: 45.0644 - mae: 3.4165 - val_loss: 50.2472 - val_mae: 3.7564\n",
      "Epoch 175/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.2516 - mae: 3.3259 - val_loss: 49.1007 - val_mae: 3.7012\n",
      "Epoch 176/500\n",
      "26/26 - 0s - 7ms/step - loss: 46.0281 - mae: 3.3366 - val_loss: 46.9431 - val_mae: 3.4337\n",
      "Epoch 177/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.2879 - mae: 3.4311 - val_loss: 48.0242 - val_mae: 3.3419\n",
      "Epoch 178/500\n",
      "26/26 - 0s - 6ms/step - loss: 45.3706 - mae: 3.4314 - val_loss: 49.5354 - val_mae: 3.8346\n",
      "Epoch 179/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.8794 - mae: 3.2726 - val_loss: 47.4170 - val_mae: 3.5714\n",
      "Epoch 180/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.2247 - mae: 3.3203 - val_loss: 46.5366 - val_mae: 3.4417\n",
      "Epoch 181/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.6633 - mae: 3.2860 - val_loss: 45.9619 - val_mae: 3.3349\n",
      "Epoch 182/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.3886 - mae: 3.3002 - val_loss: 49.0861 - val_mae: 3.7097\n",
      "Epoch 183/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.6434 - mae: 3.3061 - val_loss: 47.7621 - val_mae: 3.5704\n",
      "Epoch 184/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.0722 - mae: 3.4073 - val_loss: 45.4730 - val_mae: 3.2567\n",
      "Epoch 185/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.3059 - mae: 3.5079 - val_loss: 46.7885 - val_mae: 3.4693\n",
      "Epoch 186/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.2514 - mae: 3.2022 - val_loss: 46.7949 - val_mae: 3.3604\n",
      "Epoch 187/500\n",
      "26/26 - 0s - 6ms/step - loss: 48.1321 - mae: 3.6219 - val_loss: 48.0097 - val_mae: 3.3826\n",
      "Epoch 188/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.5751 - mae: 3.5410 - val_loss: 47.8311 - val_mae: 3.4882\n",
      "Epoch 189/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.8475 - mae: 3.4343 - val_loss: 46.2111 - val_mae: 3.4007\n",
      "Epoch 190/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.9665 - mae: 3.4384 - val_loss: 48.4872 - val_mae: 3.7002\n",
      "Epoch 191/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.5350 - mae: 3.4587 - val_loss: 49.5969 - val_mae: 3.8715\n",
      "Epoch 192/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.9474 - mae: 3.4235 - val_loss: 52.5718 - val_mae: 4.1357\n",
      "Epoch 193/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.4369 - mae: 3.3869 - val_loss: 48.7990 - val_mae: 3.6945\n",
      "Epoch 194/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.5441 - mae: 3.4190 - val_loss: 48.6390 - val_mae: 3.6770\n",
      "Epoch 195/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.6419 - mae: 3.2576 - val_loss: 46.7975 - val_mae: 3.4391\n",
      "Epoch 196/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.1695 - mae: 3.2509 - val_loss: 46.8295 - val_mae: 3.4850\n",
      "Epoch 197/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.5050 - mae: 3.4077 - val_loss: 48.3577 - val_mae: 3.6427\n",
      "Epoch 198/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.5478 - mae: 3.1985 - val_loss: 48.7440 - val_mae: 3.5980\n",
      "Epoch 199/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.0374 - mae: 3.3318 - val_loss: 48.4099 - val_mae: 3.7626\n",
      "Epoch 200/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.2474 - mae: 3.2484 - val_loss: 47.6990 - val_mae: 3.5557\n",
      "Epoch 201/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.6955 - mae: 3.1959 - val_loss: 49.6672 - val_mae: 3.7484\n",
      "Epoch 202/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.0018 - mae: 3.3203 - val_loss: 47.7832 - val_mae: 3.5343\n",
      "Epoch 203/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.9588 - mae: 3.2519 - val_loss: 48.0862 - val_mae: 3.7160\n",
      "Epoch 204/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.4290 - mae: 3.2798 - val_loss: 48.8663 - val_mae: 3.6933\n",
      "Epoch 205/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.6176 - mae: 3.3583 - val_loss: 47.3080 - val_mae: 3.4710\n",
      "Epoch 206/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.4178 - mae: 3.3171 - val_loss: 47.6333 - val_mae: 3.6453\n",
      "Epoch 207/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.7429 - mae: 3.3621 - val_loss: 47.3300 - val_mae: 3.4947\n",
      "Epoch 208/500\n",
      "26/26 - 0s - 6ms/step - loss: 45.3929 - mae: 3.4406 - val_loss: 48.2128 - val_mae: 3.5729\n",
      "Epoch 209/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.4790 - mae: 3.2005 - val_loss: 47.2587 - val_mae: 3.4933\n",
      "Epoch 210/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.5817 - mae: 3.2842 - val_loss: 45.9020 - val_mae: 3.4599\n",
      "Epoch 211/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.0555 - mae: 3.3097 - val_loss: 49.7785 - val_mae: 3.9216\n",
      "Epoch 212/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.7654 - mae: 3.3610 - val_loss: 46.2503 - val_mae: 3.3218\n",
      "Epoch 213/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.2063 - mae: 3.1537 - val_loss: 47.4194 - val_mae: 3.6453\n",
      "Epoch 214/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.3322 - mae: 3.3488 - val_loss: 45.9802 - val_mae: 3.3898\n",
      "Epoch 215/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.4320 - mae: 3.2100 - val_loss: 47.0139 - val_mae: 3.5025\n",
      "Epoch 216/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.0411 - mae: 3.4661 - val_loss: 46.7501 - val_mae: 3.4933\n",
      "Epoch 217/500\n",
      "26/26 - 0s - 13ms/step - loss: 43.5216 - mae: 3.2840 - val_loss: 46.6132 - val_mae: 3.5398\n",
      "Epoch 218/500\n",
      "26/26 - 0s - 6ms/step - loss: 47.7517 - mae: 3.5921 - val_loss: 46.1586 - val_mae: 3.3809\n",
      "Epoch 219/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.4156 - mae: 3.4275 - val_loss: 50.3109 - val_mae: 3.9985\n",
      "Epoch 220/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.4748 - mae: 3.2889 - val_loss: 46.2327 - val_mae: 3.3509\n",
      "Epoch 221/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.6038 - mae: 3.3680 - val_loss: 48.5711 - val_mae: 3.7844\n",
      "Epoch 222/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.2006 - mae: 3.2425 - val_loss: 46.6570 - val_mae: 3.4819\n",
      "Epoch 223/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.9925 - mae: 3.3553 - val_loss: 47.6646 - val_mae: 3.5790\n",
      "Epoch 224/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.6668 - mae: 3.2646 - val_loss: 44.5158 - val_mae: 3.2934\n",
      "Epoch 225/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.3187 - mae: 3.4634 - val_loss: 45.4800 - val_mae: 3.3936\n",
      "Epoch 226/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.2657 - mae: 3.4767 - val_loss: 47.0325 - val_mae: 3.4162\n",
      "Epoch 227/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.5922 - mae: 3.4277 - val_loss: 45.8318 - val_mae: 3.3211\n",
      "Epoch 228/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.8809 - mae: 3.4329 - val_loss: 46.3149 - val_mae: 3.3653\n",
      "Epoch 229/500\n",
      "26/26 - 0s - 12ms/step - loss: 44.9224 - mae: 3.4235 - val_loss: 46.2908 - val_mae: 3.4807\n",
      "Epoch 230/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.9784 - mae: 3.2866 - val_loss: 47.8551 - val_mae: 3.7479\n",
      "Epoch 231/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.3657 - mae: 3.4246 - val_loss: 47.2790 - val_mae: 3.3827\n",
      "Epoch 232/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.4339 - mae: 3.1276 - val_loss: 46.3981 - val_mae: 3.3756\n",
      "Epoch 233/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.8154 - mae: 3.1997 - val_loss: 47.4297 - val_mae: 3.6518\n",
      "Epoch 234/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.7402 - mae: 3.1600 - val_loss: 47.3091 - val_mae: 3.3472\n",
      "Epoch 235/500\n",
      "26/26 - 0s - 6ms/step - loss: 45.4861 - mae: 3.4287 - val_loss: 46.6083 - val_mae: 3.5893\n",
      "Epoch 236/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.8341 - mae: 3.2534 - val_loss: 45.7598 - val_mae: 3.4326\n",
      "Epoch 237/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.1717 - mae: 3.3595 - val_loss: 45.3672 - val_mae: 3.4951\n",
      "Epoch 238/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.9008 - mae: 3.2878 - val_loss: 44.6468 - val_mae: 3.4921\n",
      "Epoch 239/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.8151 - mae: 3.3497 - val_loss: 47.2886 - val_mae: 3.6519\n",
      "Epoch 240/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.6758 - mae: 3.4660 - val_loss: 45.9094 - val_mae: 3.3077\n",
      "Epoch 241/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.3686 - mae: 3.4601 - val_loss: 46.0823 - val_mae: 3.6043\n",
      "Epoch 242/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.1981 - mae: 3.3030 - val_loss: 45.5773 - val_mae: 3.6125\n",
      "Epoch 243/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.8966 - mae: 3.3941 - val_loss: 44.1126 - val_mae: 3.4217\n",
      "Epoch 244/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.0273 - mae: 3.3927 - val_loss: 44.5371 - val_mae: 3.3509\n",
      "Epoch 245/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.9810 - mae: 3.3384 - val_loss: 45.8679 - val_mae: 3.4139\n",
      "Epoch 246/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.1031 - mae: 3.3333 - val_loss: 44.7692 - val_mae: 3.3786\n",
      "Epoch 247/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.1388 - mae: 3.1659 - val_loss: 45.1528 - val_mae: 3.4049\n",
      "Epoch 248/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.9063 - mae: 3.3125 - val_loss: 44.8468 - val_mae: 3.4172\n",
      "Epoch 249/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.7354 - mae: 3.1454 - val_loss: 45.9332 - val_mae: 3.6483\n",
      "Epoch 250/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.7446 - mae: 3.2043 - val_loss: 45.5492 - val_mae: 3.4613\n",
      "Epoch 251/500\n",
      "26/26 - 0s - 6ms/step - loss: 45.4064 - mae: 3.4864 - val_loss: 46.8766 - val_mae: 3.6363\n",
      "Epoch 252/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.5354 - mae: 3.4204 - val_loss: 46.6543 - val_mae: 3.4641\n",
      "Epoch 253/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.7236 - mae: 3.4184 - val_loss: 48.2332 - val_mae: 3.4998\n",
      "Epoch 254/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.5839 - mae: 3.1662 - val_loss: 48.8983 - val_mae: 3.7149\n",
      "Epoch 255/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.6681 - mae: 3.2395 - val_loss: 47.2115 - val_mae: 3.6246\n",
      "Epoch 256/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.3709 - mae: 3.3275 - val_loss: 45.6280 - val_mae: 3.6015\n",
      "Epoch 257/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.9798 - mae: 3.2950 - val_loss: 45.8951 - val_mae: 3.3363\n",
      "Epoch 258/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.3192 - mae: 3.2311 - val_loss: 50.1823 - val_mae: 3.8543\n",
      "Epoch 259/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.8675 - mae: 3.2043 - val_loss: 47.9920 - val_mae: 3.4604\n",
      "Epoch 260/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.6933 - mae: 3.3014 - val_loss: 49.8336 - val_mae: 3.7296\n",
      "Epoch 261/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.9156 - mae: 3.2681 - val_loss: 46.1531 - val_mae: 3.5306\n",
      "Epoch 262/500\n",
      "26/26 - 0s - 15ms/step - loss: 39.7899 - mae: 3.2212 - val_loss: 46.3414 - val_mae: 3.5952\n",
      "Epoch 263/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.3368 - mae: 3.2790 - val_loss: 47.2030 - val_mae: 3.6212\n",
      "Epoch 264/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.0278 - mae: 3.3371 - val_loss: 48.4192 - val_mae: 3.6146\n",
      "Epoch 265/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.6938 - mae: 3.3246 - val_loss: 46.5208 - val_mae: 3.6377\n",
      "Epoch 266/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.2494 - mae: 3.2608 - val_loss: 46.1084 - val_mae: 3.4229\n",
      "Epoch 267/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.9540 - mae: 3.1932 - val_loss: 47.6651 - val_mae: 3.7294\n",
      "Epoch 268/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.1082 - mae: 3.3337 - val_loss: 46.8777 - val_mae: 3.3836\n",
      "Epoch 269/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.4979 - mae: 3.1108 - val_loss: 46.3174 - val_mae: 3.5993\n",
      "Epoch 270/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.4712 - mae: 3.1308 - val_loss: 45.7728 - val_mae: 3.4975\n",
      "Epoch 271/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.9690 - mae: 3.2620 - val_loss: 45.1412 - val_mae: 3.4746\n",
      "Epoch 272/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.2421 - mae: 3.3874 - val_loss: 47.2359 - val_mae: 3.7098\n",
      "Epoch 273/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.5450 - mae: 3.5292 - val_loss: 47.4867 - val_mae: 3.6878\n",
      "Epoch 274/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.9525 - mae: 3.2818 - val_loss: 45.8478 - val_mae: 3.3447\n",
      "Epoch 275/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.4022 - mae: 3.2519 - val_loss: 45.3105 - val_mae: 3.4590\n",
      "Epoch 276/500\n",
      "26/26 - 0s - 12ms/step - loss: 45.2333 - mae: 3.4203 - val_loss: 49.8946 - val_mae: 4.0686\n",
      "Epoch 277/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.8675 - mae: 3.2587 - val_loss: 46.2703 - val_mae: 3.5179\n",
      "Epoch 278/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.5145 - mae: 3.3738 - val_loss: 48.3945 - val_mae: 3.8399\n",
      "Epoch 279/500\n",
      "26/26 - 0s - 7ms/step - loss: 42.1837 - mae: 3.2946 - val_loss: 44.9208 - val_mae: 3.4163\n",
      "Epoch 280/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.6485 - mae: 3.3705 - val_loss: 43.6071 - val_mae: 3.4290\n",
      "Epoch 281/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.6282 - mae: 3.4267 - val_loss: 45.2030 - val_mae: 3.5542\n",
      "Epoch 282/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.8961 - mae: 3.3778 - val_loss: 44.0592 - val_mae: 3.4057\n",
      "Epoch 283/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.1943 - mae: 3.1841 - val_loss: 44.5283 - val_mae: 3.3316\n",
      "Epoch 284/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.8006 - mae: 3.3284 - val_loss: 46.1682 - val_mae: 3.4148\n",
      "Epoch 285/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.1704 - mae: 3.2013 - val_loss: 46.2704 - val_mae: 3.6707\n",
      "Epoch 286/500\n",
      "26/26 - 0s - 7ms/step - loss: 42.3740 - mae: 3.3548 - val_loss: 45.1854 - val_mae: 3.5911\n",
      "Epoch 287/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.7690 - mae: 3.2876 - val_loss: 45.5538 - val_mae: 3.5802\n",
      "Epoch 288/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.4359 - mae: 3.2427 - val_loss: 44.6982 - val_mae: 3.4712\n",
      "Epoch 289/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.7808 - mae: 3.2996 - val_loss: 42.8274 - val_mae: 3.2823\n",
      "Epoch 290/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.0831 - mae: 3.2458 - val_loss: 45.0016 - val_mae: 3.5594\n",
      "Epoch 291/500\n",
      "26/26 - 0s - 6ms/step - loss: 46.1726 - mae: 3.6439 - val_loss: 46.1618 - val_mae: 3.3457\n",
      "Epoch 292/500\n",
      "26/26 - 0s - 12ms/step - loss: 40.5121 - mae: 3.1686 - val_loss: 47.5123 - val_mae: 3.8038\n",
      "Epoch 293/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.3566 - mae: 3.2213 - val_loss: 50.0946 - val_mae: 4.0999\n",
      "Epoch 294/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.0671 - mae: 3.2478 - val_loss: 45.3192 - val_mae: 3.3502\n",
      "Epoch 295/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.5326 - mae: 3.0878 - val_loss: 44.3508 - val_mae: 3.3809\n",
      "Epoch 296/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.2141 - mae: 3.1614 - val_loss: 44.7886 - val_mae: 3.3555\n",
      "Epoch 297/500\n",
      "26/26 - 0s - 7ms/step - loss: 44.0590 - mae: 3.4825 - val_loss: 46.6531 - val_mae: 3.5107\n",
      "Epoch 298/500\n",
      "26/26 - 0s - 12ms/step - loss: 39.2654 - mae: 3.2012 - val_loss: 47.7976 - val_mae: 3.7074\n",
      "Epoch 299/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.7147 - mae: 3.1800 - val_loss: 46.5347 - val_mae: 3.4677\n",
      "Epoch 300/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.8482 - mae: 3.2811 - val_loss: 49.0265 - val_mae: 3.7570\n",
      "Epoch 301/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.7802 - mae: 3.0270 - val_loss: 47.4239 - val_mae: 3.6561\n",
      "Epoch 302/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.8010 - mae: 3.3605 - val_loss: 47.0177 - val_mae: 3.5776\n",
      "Epoch 303/500\n",
      "26/26 - 0s - 12ms/step - loss: 37.2477 - mae: 3.0833 - val_loss: 49.4191 - val_mae: 3.9962\n",
      "Epoch 304/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.8435 - mae: 3.2694 - val_loss: 47.5162 - val_mae: 3.5260\n",
      "Epoch 305/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.1763 - mae: 3.4131 - val_loss: 47.9672 - val_mae: 3.8160\n",
      "Epoch 306/500\n",
      "26/26 - 0s - 9ms/step - loss: 38.1691 - mae: 3.1271 - val_loss: 45.7554 - val_mae: 3.4640\n",
      "Epoch 307/500\n",
      "26/26 - 0s - 7ms/step - loss: 41.9022 - mae: 3.2783 - val_loss: 46.0914 - val_mae: 3.6226\n",
      "Epoch 308/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.6761 - mae: 3.2073 - val_loss: 47.3644 - val_mae: 3.6448\n",
      "Epoch 309/500\n",
      "26/26 - 0s - 12ms/step - loss: 42.3840 - mae: 3.4438 - val_loss: 48.1807 - val_mae: 3.7553\n",
      "Epoch 310/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.4254 - mae: 3.2869 - val_loss: 46.0976 - val_mae: 3.4849\n",
      "Epoch 311/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.2252 - mae: 3.3377 - val_loss: 47.5245 - val_mae: 3.7820\n",
      "Epoch 312/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.1439 - mae: 3.2194 - val_loss: 44.6047 - val_mae: 3.3709\n",
      "Epoch 313/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.7980 - mae: 3.2534 - val_loss: 45.4657 - val_mae: 3.4111\n",
      "Epoch 314/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.2312 - mae: 3.4680 - val_loss: 47.7380 - val_mae: 3.8258\n",
      "Epoch 315/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.6175 - mae: 3.3329 - val_loss: 44.9799 - val_mae: 3.3950\n",
      "Epoch 316/500\n",
      "26/26 - 0s - 7ms/step - loss: 42.7598 - mae: 3.3187 - val_loss: 45.1128 - val_mae: 3.5806\n",
      "Epoch 317/500\n",
      "26/26 - 0s - 7ms/step - loss: 41.7773 - mae: 3.3255 - val_loss: 45.8113 - val_mae: 3.6167\n",
      "Epoch 318/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.5640 - mae: 3.3159 - val_loss: 47.7913 - val_mae: 3.7044\n",
      "Epoch 319/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.9448 - mae: 3.2030 - val_loss: 46.7611 - val_mae: 3.7337\n",
      "Epoch 320/500\n",
      "26/26 - 0s - 7ms/step - loss: 37.7753 - mae: 3.0574 - val_loss: 46.0423 - val_mae: 3.4663\n",
      "Epoch 321/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.7328 - mae: 3.3503 - val_loss: 45.4659 - val_mae: 3.5862\n",
      "Epoch 322/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.3047 - mae: 3.2035 - val_loss: 45.6300 - val_mae: 3.3850\n",
      "Epoch 323/500\n",
      "26/26 - 0s - 7ms/step - loss: 42.7265 - mae: 3.3874 - val_loss: 46.8220 - val_mae: 3.5696\n",
      "Epoch 324/500\n",
      "26/26 - 0s - 12ms/step - loss: 41.3553 - mae: 3.2455 - val_loss: 46.1978 - val_mae: 3.7488\n",
      "Epoch 325/500\n",
      "26/26 - 0s - 11ms/step - loss: 39.7730 - mae: 3.2981 - val_loss: 46.3992 - val_mae: 3.5600\n",
      "Epoch 326/500\n",
      "26/26 - 0s - 8ms/step - loss: 38.7139 - mae: 3.2141 - val_loss: 46.1851 - val_mae: 3.6013\n",
      "Epoch 327/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.4508 - mae: 3.1726 - val_loss: 45.6688 - val_mae: 3.5865\n",
      "Epoch 328/500\n",
      "26/26 - 0s - 12ms/step - loss: 42.9357 - mae: 3.4007 - val_loss: 44.2031 - val_mae: 3.4564\n",
      "Epoch 329/500\n",
      "26/26 - 0s - 9ms/step - loss: 38.4270 - mae: 3.2211 - val_loss: 44.3488 - val_mae: 3.4657\n",
      "Epoch 330/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.3745 - mae: 3.2713 - val_loss: 46.5987 - val_mae: 3.4297\n",
      "Epoch 331/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.8305 - mae: 3.2557 - val_loss: 47.4093 - val_mae: 3.6674\n",
      "Epoch 332/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.3489 - mae: 3.3032 - val_loss: 46.8939 - val_mae: 3.4441\n",
      "Epoch 333/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.7572 - mae: 3.2849 - val_loss: 47.3601 - val_mae: 3.7109\n",
      "Epoch 334/500\n",
      "26/26 - 0s - 10ms/step - loss: 41.5650 - mae: 3.3819 - val_loss: 44.7350 - val_mae: 3.4271\n",
      "Epoch 335/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.0357 - mae: 3.3790 - val_loss: 46.3439 - val_mae: 3.6079\n",
      "Epoch 336/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.8848 - mae: 3.2428 - val_loss: 46.6097 - val_mae: 3.7111\n",
      "Epoch 337/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.0594 - mae: 3.2438 - val_loss: 46.9536 - val_mae: 3.6781\n",
      "Epoch 338/500\n",
      "26/26 - 0s - 7ms/step - loss: 41.4791 - mae: 3.2505 - val_loss: 45.5070 - val_mae: 3.6520\n",
      "Epoch 339/500\n",
      "26/26 - 0s - 11ms/step - loss: 41.6510 - mae: 3.2607 - val_loss: 45.6770 - val_mae: 3.6361\n",
      "Epoch 340/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.7110 - mae: 3.4472 - val_loss: 45.3890 - val_mae: 3.6625\n",
      "Epoch 341/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.9085 - mae: 3.1821 - val_loss: 44.6017 - val_mae: 3.4338\n",
      "Epoch 342/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.6820 - mae: 3.2657 - val_loss: 47.6468 - val_mae: 3.9255\n",
      "Epoch 343/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.4207 - mae: 3.4451 - val_loss: 43.3785 - val_mae: 3.3987\n",
      "Epoch 344/500\n",
      "26/26 - 0s - 6ms/step - loss: 36.5981 - mae: 3.0577 - val_loss: 44.3148 - val_mae: 3.4356\n",
      "Epoch 345/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.5130 - mae: 3.2957 - val_loss: 45.3985 - val_mae: 3.5790\n",
      "Epoch 346/500\n",
      "26/26 - 0s - 6ms/step - loss: 36.5613 - mae: 2.9973 - val_loss: 43.0826 - val_mae: 3.3255\n",
      "Epoch 347/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.8811 - mae: 3.2305 - val_loss: 44.1051 - val_mae: 3.4654\n",
      "Epoch 348/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.6493 - mae: 3.2396 - val_loss: 44.1341 - val_mae: 3.4841\n",
      "Epoch 349/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.7617 - mae: 3.2443 - val_loss: 46.8510 - val_mae: 3.7739\n",
      "Epoch 350/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.9705 - mae: 3.3548 - val_loss: 45.3316 - val_mae: 3.6366\n",
      "Epoch 351/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.0952 - mae: 3.1111 - val_loss: 43.9078 - val_mae: 3.4806\n",
      "Epoch 352/500\n",
      "26/26 - 0s - 7ms/step - loss: 37.3901 - mae: 3.1239 - val_loss: 45.2087 - val_mae: 3.5744\n",
      "Epoch 353/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.7227 - mae: 3.3618 - val_loss: 45.7893 - val_mae: 3.5022\n",
      "Epoch 354/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.9309 - mae: 3.2372 - val_loss: 44.4226 - val_mae: 3.3886\n",
      "Epoch 355/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.8503 - mae: 3.5777 - val_loss: 42.6324 - val_mae: 3.3838\n",
      "Epoch 356/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.6729 - mae: 3.2589 - val_loss: 45.0787 - val_mae: 3.7344\n",
      "Epoch 357/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.4821 - mae: 3.3087 - val_loss: 42.9301 - val_mae: 3.2952\n",
      "Epoch 358/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.8606 - mae: 3.4934 - val_loss: 44.5611 - val_mae: 3.5380\n",
      "Epoch 359/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.9123 - mae: 3.1909 - val_loss: 43.4711 - val_mae: 3.3514\n",
      "Epoch 360/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.7646 - mae: 3.1603 - val_loss: 45.0919 - val_mae: 3.5610\n",
      "Epoch 361/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.7750 - mae: 3.1906 - val_loss: 44.8918 - val_mae: 3.5031\n",
      "Epoch 362/500\n",
      "26/26 - 0s - 7ms/step - loss: 37.8409 - mae: 3.2683 - val_loss: 48.5737 - val_mae: 3.8897\n",
      "Epoch 363/500\n",
      "26/26 - 0s - 7ms/step - loss: 43.4368 - mae: 3.3518 - val_loss: 46.4738 - val_mae: 3.8489\n",
      "Epoch 364/500\n",
      "26/26 - 0s - 6ms/step - loss: 50.8132 - mae: 3.8249 - val_loss: 42.9095 - val_mae: 3.5081\n",
      "Epoch 365/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.4104 - mae: 3.3983 - val_loss: 41.3922 - val_mae: 3.3101\n",
      "Epoch 366/500\n",
      "26/26 - 0s - 7ms/step - loss: 42.3313 - mae: 3.3674 - val_loss: 44.4370 - val_mae: 3.6694\n",
      "Epoch 367/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.6969 - mae: 3.2513 - val_loss: 42.6235 - val_mae: 3.3728\n",
      "Epoch 368/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.5817 - mae: 3.3466 - val_loss: 43.5035 - val_mae: 3.3585\n",
      "Epoch 369/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.6740 - mae: 3.4385 - val_loss: 43.4511 - val_mae: 3.4559\n",
      "Epoch 370/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.1582 - mae: 3.1433 - val_loss: 42.7806 - val_mae: 3.4125\n",
      "Epoch 371/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.0362 - mae: 3.2300 - val_loss: 43.4097 - val_mae: 3.4602\n",
      "Epoch 372/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.7132 - mae: 3.3099 - val_loss: 43.3888 - val_mae: 3.3484\n",
      "Epoch 373/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.5044 - mae: 3.5115 - val_loss: 46.0937 - val_mae: 3.7061\n",
      "Epoch 374/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.0406 - mae: 3.3056 - val_loss: 45.1392 - val_mae: 3.4216\n",
      "Epoch 375/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.4396 - mae: 3.3893 - val_loss: 46.8424 - val_mae: 3.8524\n",
      "Epoch 376/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.6719 - mae: 3.3362 - val_loss: 44.2664 - val_mae: 3.5211\n",
      "Epoch 377/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.3449 - mae: 3.2235 - val_loss: 44.6549 - val_mae: 3.6683\n",
      "Epoch 378/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.0286 - mae: 3.1729 - val_loss: 44.3749 - val_mae: 3.4754\n",
      "Epoch 379/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.9790 - mae: 3.3280 - val_loss: 47.1290 - val_mae: 3.6221\n",
      "Epoch 380/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.8546 - mae: 3.1895 - val_loss: 47.3683 - val_mae: 3.8597\n",
      "Epoch 381/500\n",
      "26/26 - 0s - 6ms/step - loss: 35.8648 - mae: 3.0425 - val_loss: 43.8723 - val_mae: 3.4663\n",
      "Epoch 382/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.2309 - mae: 3.3436 - val_loss: 47.7125 - val_mae: 3.9502\n",
      "Epoch 383/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.4630 - mae: 3.3328 - val_loss: 46.8470 - val_mae: 3.8623\n",
      "Epoch 384/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.5254 - mae: 3.4423 - val_loss: 44.8587 - val_mae: 3.4355\n",
      "Epoch 385/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.7881 - mae: 3.2202 - val_loss: 44.7151 - val_mae: 3.6370\n",
      "Epoch 386/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.2422 - mae: 3.1638 - val_loss: 43.5638 - val_mae: 3.3356\n",
      "Epoch 387/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.3233 - mae: 3.3662 - val_loss: 45.2741 - val_mae: 3.7161\n",
      "Epoch 388/500\n",
      "26/26 - 0s - 13ms/step - loss: 43.9276 - mae: 3.4615 - val_loss: 45.4880 - val_mae: 3.7599\n",
      "Epoch 389/500\n",
      "26/26 - 0s - 12ms/step - loss: 40.6844 - mae: 3.3406 - val_loss: 45.1279 - val_mae: 3.6297\n",
      "Epoch 390/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.4904 - mae: 3.3127 - val_loss: 44.9517 - val_mae: 3.4178\n",
      "Epoch 391/500\n",
      "26/26 - 0s - 6ms/step - loss: 41.7989 - mae: 3.3687 - val_loss: 44.4739 - val_mae: 3.5647\n",
      "Epoch 392/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.1950 - mae: 3.3285 - val_loss: 43.2726 - val_mae: 3.5119\n",
      "Epoch 393/500\n",
      "26/26 - 0s - 7ms/step - loss: 37.3528 - mae: 3.0995 - val_loss: 43.4079 - val_mae: 3.4488\n",
      "Epoch 394/500\n",
      "26/26 - 0s - 7ms/step - loss: 42.2550 - mae: 3.3810 - val_loss: 45.2243 - val_mae: 3.6839\n",
      "Epoch 395/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.5456 - mae: 3.2067 - val_loss: 44.4697 - val_mae: 3.5775\n",
      "Epoch 396/500\n",
      "26/26 - 0s - 7ms/step - loss: 42.6735 - mae: 3.4874 - val_loss: 44.2461 - val_mae: 3.4269\n",
      "Epoch 397/500\n",
      "26/26 - 0s - 7ms/step - loss: 42.4412 - mae: 3.4164 - val_loss: 44.4119 - val_mae: 3.5530\n",
      "Epoch 398/500\n",
      "26/26 - 0s - 7ms/step - loss: 45.9247 - mae: 3.5303 - val_loss: 44.0673 - val_mae: 3.5266\n",
      "Epoch 399/500\n",
      "26/26 - 0s - 7ms/step - loss: 42.9454 - mae: 3.4803 - val_loss: 44.4129 - val_mae: 3.6115\n",
      "Epoch 400/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.4934 - mae: 3.1595 - val_loss: 45.2833 - val_mae: 3.5252\n",
      "Epoch 401/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.4735 - mae: 3.1811 - val_loss: 45.1941 - val_mae: 3.6160\n",
      "Epoch 402/500\n",
      "26/26 - 0s - 6ms/step - loss: 44.1416 - mae: 3.4690 - val_loss: 45.1755 - val_mae: 3.6596\n",
      "Epoch 403/500\n",
      "26/26 - 0s - 8ms/step - loss: 41.5106 - mae: 3.3756 - val_loss: 44.9174 - val_mae: 3.5266\n",
      "Epoch 404/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.8389 - mae: 3.2465 - val_loss: 48.1809 - val_mae: 3.9945\n",
      "Epoch 405/500\n",
      "26/26 - 0s - 12ms/step - loss: 41.6284 - mae: 3.3665 - val_loss: 47.4337 - val_mae: 3.9839\n",
      "Epoch 406/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.3117 - mae: 3.3149 - val_loss: 43.3260 - val_mae: 3.4117\n",
      "Epoch 407/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.6742 - mae: 3.2460 - val_loss: 45.4463 - val_mae: 3.7622\n",
      "Epoch 408/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.1512 - mae: 3.2121 - val_loss: 44.2865 - val_mae: 3.6453\n",
      "Epoch 409/500\n",
      "26/26 - 0s - 6ms/step - loss: 43.3364 - mae: 3.5079 - val_loss: 42.5434 - val_mae: 3.3357\n",
      "Epoch 410/500\n",
      "26/26 - 0s - 10ms/step - loss: 41.7498 - mae: 3.3056 - val_loss: 45.5083 - val_mae: 3.7883\n",
      "Epoch 411/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.6523 - mae: 3.2972 - val_loss: 43.4168 - val_mae: 3.4515\n",
      "Epoch 412/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.1180 - mae: 3.3072 - val_loss: 43.2679 - val_mae: 3.3736\n",
      "Epoch 413/500\n",
      "26/26 - 0s - 7ms/step - loss: 41.9459 - mae: 3.3282 - val_loss: 43.7077 - val_mae: 3.5786\n",
      "Epoch 414/500\n",
      "26/26 - 0s - 13ms/step - loss: 38.7708 - mae: 3.2322 - val_loss: 41.9447 - val_mae: 3.3288\n",
      "Epoch 415/500\n",
      "26/26 - 0s - 8ms/step - loss: 39.6987 - mae: 3.2664 - val_loss: 41.8418 - val_mae: 3.3530\n",
      "Epoch 416/500\n",
      "26/26 - 0s - 6ms/step - loss: 36.3954 - mae: 3.1200 - val_loss: 42.1798 - val_mae: 3.3643\n",
      "Epoch 417/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.1933 - mae: 3.1518 - val_loss: 42.7448 - val_mae: 3.3182\n",
      "Epoch 418/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.2980 - mae: 3.2040 - val_loss: 43.5303 - val_mae: 3.5530\n",
      "Epoch 419/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.4000 - mae: 3.3482 - val_loss: 43.0206 - val_mae: 3.3884\n",
      "Epoch 420/500\n",
      "26/26 - 0s - 12ms/step - loss: 42.8465 - mae: 3.4167 - val_loss: 44.3766 - val_mae: 3.4074\n",
      "Epoch 421/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.0060 - mae: 3.1697 - val_loss: 45.3104 - val_mae: 3.4724\n",
      "Epoch 422/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.0286 - mae: 3.2090 - val_loss: 45.8521 - val_mae: 3.6007\n",
      "Epoch 423/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.3448 - mae: 3.2287 - val_loss: 45.6801 - val_mae: 3.5985\n",
      "Epoch 424/500\n",
      "26/26 - 0s - 8ms/step - loss: 37.4300 - mae: 3.2566 - val_loss: 41.8832 - val_mae: 3.3724\n",
      "Epoch 425/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.0141 - mae: 3.3257 - val_loss: 42.9075 - val_mae: 3.5085\n",
      "Epoch 426/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.9029 - mae: 3.2390 - val_loss: 42.9801 - val_mae: 3.4727\n",
      "Epoch 427/500\n",
      "26/26 - 0s - 8ms/step - loss: 36.8973 - mae: 3.1282 - val_loss: 42.7574 - val_mae: 3.3979\n",
      "Epoch 428/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.1653 - mae: 3.3593 - val_loss: 44.7792 - val_mae: 3.7294\n",
      "Epoch 429/500\n",
      "26/26 - 0s - 8ms/step - loss: 39.3866 - mae: 3.3166 - val_loss: 42.5951 - val_mae: 3.3733\n",
      "Epoch 430/500\n",
      "26/26 - 0s - 8ms/step - loss: 42.7545 - mae: 3.3604 - val_loss: 44.7412 - val_mae: 3.4781\n",
      "Epoch 431/500\n",
      "26/26 - 0s - 7ms/step - loss: 35.8376 - mae: 3.0264 - val_loss: 43.7678 - val_mae: 3.4654\n",
      "Epoch 432/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.9731 - mae: 3.3976 - val_loss: 44.6835 - val_mae: 3.6288\n",
      "Epoch 433/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.7929 - mae: 3.3152 - val_loss: 42.5759 - val_mae: 3.3273\n",
      "Epoch 434/500\n",
      "26/26 - 0s - 7ms/step - loss: 37.2014 - mae: 3.1156 - val_loss: 44.1516 - val_mae: 3.6210\n",
      "Epoch 435/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.2642 - mae: 3.3248 - val_loss: 41.8475 - val_mae: 3.2869\n",
      "Epoch 436/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.2742 - mae: 3.2799 - val_loss: 44.5138 - val_mae: 3.4242\n",
      "Epoch 437/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.7162 - mae: 3.3227 - val_loss: 42.7700 - val_mae: 3.3860\n",
      "Epoch 438/500\n",
      "26/26 - 0s - 13ms/step - loss: 40.9999 - mae: 3.2607 - val_loss: 43.8350 - val_mae: 3.6754\n",
      "Epoch 439/500\n",
      "26/26 - 0s - 7ms/step - loss: 43.2673 - mae: 3.5082 - val_loss: 43.3484 - val_mae: 3.5256\n",
      "Epoch 440/500\n",
      "26/26 - 0s - 7ms/step - loss: 43.2149 - mae: 3.5193 - val_loss: 42.2968 - val_mae: 3.3998\n",
      "Epoch 441/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.8001 - mae: 3.2554 - val_loss: 41.4583 - val_mae: 3.2568\n",
      "Epoch 442/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.5853 - mae: 3.2282 - val_loss: 45.2697 - val_mae: 3.4643\n",
      "Epoch 443/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.5271 - mae: 3.2359 - val_loss: 42.2060 - val_mae: 3.3542\n",
      "Epoch 444/500\n",
      "26/26 - 1s - 25ms/step - loss: 43.0509 - mae: 3.4182 - val_loss: 44.2705 - val_mae: 3.6095\n",
      "Epoch 445/500\n",
      "26/26 - 0s - 8ms/step - loss: 34.7704 - mae: 2.9743 - val_loss: 41.6796 - val_mae: 3.3611\n",
      "Epoch 446/500\n",
      "26/26 - 0s - 7ms/step - loss: 41.7369 - mae: 3.3733 - val_loss: 44.2006 - val_mae: 3.5349\n",
      "Epoch 447/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.2424 - mae: 3.2371 - val_loss: 43.6558 - val_mae: 3.4069\n",
      "Epoch 448/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.5018 - mae: 3.2411 - val_loss: 44.9080 - val_mae: 3.7335\n",
      "Epoch 449/500\n",
      "26/26 - 0s - 7ms/step - loss: 43.6823 - mae: 3.3716 - val_loss: 42.5188 - val_mae: 3.4622\n",
      "Epoch 450/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.1815 - mae: 3.1822 - val_loss: 42.4516 - val_mae: 3.3019\n",
      "Epoch 451/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.1345 - mae: 3.3564 - val_loss: 44.4017 - val_mae: 3.6487\n",
      "Epoch 452/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.7356 - mae: 3.3868 - val_loss: 46.5219 - val_mae: 3.8631\n",
      "Epoch 453/500\n",
      "26/26 - 0s - 7ms/step - loss: 44.8923 - mae: 3.5655 - val_loss: 44.9932 - val_mae: 3.5994\n",
      "Epoch 454/500\n",
      "26/26 - 0s - 7ms/step - loss: 37.7506 - mae: 3.1942 - val_loss: 43.8245 - val_mae: 3.5625\n",
      "Epoch 455/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.5837 - mae: 3.2820 - val_loss: 43.0127 - val_mae: 3.4646\n",
      "Epoch 456/500\n",
      "26/26 - 0s - 7ms/step - loss: 41.9614 - mae: 3.4793 - val_loss: 45.1125 - val_mae: 3.5605\n",
      "Epoch 457/500\n",
      "26/26 - 0s - 8ms/step - loss: 38.2588 - mae: 3.1360 - val_loss: 45.9656 - val_mae: 3.6658\n",
      "Epoch 458/500\n",
      "26/26 - 0s - 8ms/step - loss: 40.4530 - mae: 3.3848 - val_loss: 47.4746 - val_mae: 4.0051\n",
      "Epoch 459/500\n",
      "26/26 - 0s - 11ms/step - loss: 37.3032 - mae: 3.1744 - val_loss: 42.5185 - val_mae: 3.4013\n",
      "Epoch 460/500\n",
      "26/26 - 0s - 14ms/step - loss: 39.3065 - mae: 3.3286 - val_loss: 43.3286 - val_mae: 3.3968\n",
      "Epoch 461/500\n",
      "26/26 - 0s - 8ms/step - loss: 39.8819 - mae: 3.2673 - val_loss: 46.2210 - val_mae: 3.8001\n",
      "Epoch 462/500\n",
      "26/26 - 0s - 8ms/step - loss: 36.5578 - mae: 3.1317 - val_loss: 43.7419 - val_mae: 3.4169\n",
      "Epoch 463/500\n",
      "26/26 - 0s - 7ms/step - loss: 36.6629 - mae: 3.1105 - val_loss: 45.1423 - val_mae: 3.6084\n",
      "Epoch 464/500\n",
      "26/26 - 0s - 7ms/step - loss: 37.0290 - mae: 3.1750 - val_loss: 45.5348 - val_mae: 3.7195\n",
      "Epoch 465/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.6799 - mae: 3.4137 - val_loss: 43.5309 - val_mae: 3.4554\n",
      "Epoch 466/500\n",
      "26/26 - 0s - 7ms/step - loss: 35.8605 - mae: 3.0150 - val_loss: 44.1709 - val_mae: 3.4183\n",
      "Epoch 467/500\n",
      "26/26 - 0s - 8ms/step - loss: 37.3677 - mae: 3.2891 - val_loss: 44.2220 - val_mae: 3.6085\n",
      "Epoch 468/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.8763 - mae: 3.2082 - val_loss: 45.5341 - val_mae: 3.7393\n",
      "Epoch 469/500\n",
      "26/26 - 0s - 12ms/step - loss: 39.0119 - mae: 3.3417 - val_loss: 43.3785 - val_mae: 3.4251\n",
      "Epoch 470/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.0342 - mae: 3.2114 - val_loss: 43.2330 - val_mae: 3.4816\n",
      "Epoch 471/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.6127 - mae: 3.3520 - val_loss: 43.7415 - val_mae: 3.4089\n",
      "Epoch 472/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.8282 - mae: 3.2635 - val_loss: 42.2728 - val_mae: 3.4225\n",
      "Epoch 473/500\n",
      "26/26 - 0s - 12ms/step - loss: 38.8021 - mae: 3.2318 - val_loss: 42.9227 - val_mae: 3.3594\n",
      "Epoch 474/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.2684 - mae: 3.2319 - val_loss: 40.7298 - val_mae: 3.1841\n",
      "Epoch 475/500\n",
      "26/26 - 0s - 8ms/step - loss: 40.4982 - mae: 3.3553 - val_loss: 42.3848 - val_mae: 3.4828\n",
      "Epoch 476/500\n",
      "26/26 - 0s - 11ms/step - loss: 37.0758 - mae: 3.2057 - val_loss: 42.3243 - val_mae: 3.4839\n",
      "Epoch 477/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.8232 - mae: 3.3110 - val_loss: 41.2689 - val_mae: 3.2564\n",
      "Epoch 478/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.7147 - mae: 3.4146 - val_loss: 42.9942 - val_mae: 3.4282\n",
      "Epoch 479/500\n",
      "26/26 - 0s - 8ms/step - loss: 39.9817 - mae: 3.3338 - val_loss: 43.3715 - val_mae: 3.4329\n",
      "Epoch 480/500\n",
      "26/26 - 0s - 8ms/step - loss: 38.4097 - mae: 3.1967 - val_loss: 43.8528 - val_mae: 3.3696\n",
      "Epoch 481/500\n",
      "26/26 - 0s - 7ms/step - loss: 43.0505 - mae: 3.5167 - val_loss: 46.4939 - val_mae: 3.7355\n",
      "Epoch 482/500\n",
      "26/26 - 0s - 7ms/step - loss: 40.1451 - mae: 3.3523 - val_loss: 45.3127 - val_mae: 3.5119\n",
      "Epoch 483/500\n",
      "26/26 - 0s - 6ms/step - loss: 36.5265 - mae: 3.0831 - val_loss: 44.5303 - val_mae: 3.5461\n",
      "Epoch 484/500\n",
      "26/26 - 0s - 8ms/step - loss: 38.5007 - mae: 3.2326 - val_loss: 45.0343 - val_mae: 3.6108\n",
      "Epoch 485/500\n",
      "26/26 - 0s - 7ms/step - loss: 41.0150 - mae: 3.3954 - val_loss: 45.4376 - val_mae: 3.5972\n",
      "Epoch 486/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.1059 - mae: 3.1453 - val_loss: 44.2252 - val_mae: 3.5116\n",
      "Epoch 487/500\n",
      "26/26 - 0s - 7ms/step - loss: 37.9227 - mae: 3.2141 - val_loss: 43.9830 - val_mae: 3.3590\n",
      "Epoch 488/500\n",
      "26/26 - 0s - 7ms/step - loss: 43.9324 - mae: 3.5318 - val_loss: 46.9143 - val_mae: 3.9533\n",
      "Epoch 489/500\n",
      "26/26 - 0s - 7ms/step - loss: 37.2940 - mae: 3.1905 - val_loss: 43.1563 - val_mae: 3.5492\n",
      "Epoch 490/500\n",
      "26/26 - 0s - 6ms/step - loss: 38.1643 - mae: 3.2079 - val_loss: 42.5583 - val_mae: 3.4343\n",
      "Epoch 491/500\n",
      "26/26 - 0s - 7ms/step - loss: 39.4028 - mae: 3.2548 - val_loss: 42.7073 - val_mae: 3.3022\n",
      "Epoch 492/500\n",
      "26/26 - 0s - 6ms/step - loss: 36.1558 - mae: 3.0997 - val_loss: 43.2759 - val_mae: 3.4509\n",
      "Epoch 493/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.2013 - mae: 3.1271 - val_loss: 44.5862 - val_mae: 3.6209\n",
      "Epoch 494/500\n",
      "26/26 - 0s - 6ms/step - loss: 42.2199 - mae: 3.3413 - val_loss: 43.8363 - val_mae: 3.6410\n",
      "Epoch 495/500\n",
      "26/26 - 0s - 6ms/step - loss: 37.4866 - mae: 3.1709 - val_loss: 42.9821 - val_mae: 3.4854\n",
      "Epoch 496/500\n",
      "26/26 - 0s - 7ms/step - loss: 38.6672 - mae: 3.3414 - val_loss: 45.1988 - val_mae: 3.7507\n",
      "Epoch 497/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.5617 - mae: 3.2818 - val_loss: 45.0049 - val_mae: 3.7042\n",
      "Epoch 498/500\n",
      "26/26 - 0s - 6ms/step - loss: 39.9159 - mae: 3.2078 - val_loss: 43.9896 - val_mae: 3.5571\n",
      "Epoch 499/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.0284 - mae: 3.2907 - val_loss: 42.5781 - val_mae: 3.3367\n",
      "Epoch 500/500\n",
      "26/26 - 0s - 6ms/step - loss: 40.9464 - mae: 3.3026 - val_loss: 44.0555 - val_mae: 3.6006\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020F20FBE700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020F20FBE700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "# Create and train model.\n",
    "\n",
    "LAMBDA = 0.2\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', kernel_regularizer=l1_l2(LAMBDA, LAMBDA), input_shape=[raw_x_train.shape[1]]),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l1_l2(LAMBDA, LAMBDA)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l1_l2(LAMBDA, LAMBDA)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l1_l2(LAMBDA, LAMBDA)),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2, shuffle=True)\n",
    "\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retry the above using dropout regularization.  What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above by trying multiple parameter combinations:\n",
    "- Using a combination of 64 to 128 neurons \n",
    "- Using Dropout of 0.2 and 0.3\n",
    "- Using L2 = 0.1 and 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For each case, print first 4 predictions and record the answers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  15.898713 , true value:  7.2\n",
      "Prediction:  18.259224 , true value:  18.8\n",
      "Prediction:  20.246407 , true value:  19.0\n",
      "Prediction:  33.0872 , true value:  27.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 4):\n",
    "    print('Prediction: ', predictions[i, 0],\n",
    "          ', true value: ', y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lamda: 0.1\n",
    "dropout:0.2\n",
    "Prediction:  13.94176 , true value:  7.2\n",
    "Prediction:  19.111694 , true value:  18.8\n",
    "Prediction:  20.371693 , true value:  19.0\n",
    "Prediction:  34.412743 , true value:  27.0\n",
    "\n",
    "lamda:0.2\n",
    "dropout: 0.3\n",
    "Prediction:  15.898713 , true value:  7.2\n",
    "Prediction:  18.259224 , true value:  18.8\n",
    "Prediction:  20.246407 , true value:  19.0\n",
    "Prediction:  33.0872 , true value:  27.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after increasing the layers ther is a defenit increase in the performance \n",
    "as for lamda and the dropout experiment (lamda 0.1 and dropout 0.3) is better than the first trial "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
